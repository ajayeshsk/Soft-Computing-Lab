{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01ea614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79e0a92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_0 = np.array([[1, -1],\n",
    "                [-1, -1]], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "972991eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_1 = np.array([[1, 0],], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50371761",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 1],\n",
    "              [0, 1],], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ec697a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.array([[0.5, 1],], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d989bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_1 = 'BSigmoid'\n",
    "f_2 = 'USigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "252fe542",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d2fc18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def USigmoid(x, direction):\n",
    "    if direction == 'F':\n",
    "        return 1/(1 + np.exp(-x))\n",
    "    else:\n",
    "        return USigmoid(x, 'F')*(1-USigmoid(x, 'F'))\n",
    "\n",
    "def BSigmoid(x, direction):\n",
    "    if direction == 'F':\n",
    "        return (1 - np.exp(-x))/(1 + np.exp(-x))\n",
    "    else:\n",
    "        return 0.5*(1-BSigmoid(x, 'F')**2) \n",
    "\n",
    "def Tanh(x, direction):\n",
    "    if direction == 'F':\n",
    "        return (1 - np.exp(-x))/(1 + np.exp(-x))\n",
    "    else:\n",
    "        return 0.5*(1-Tanh(x, 'F')**2) \n",
    "\n",
    "def ReLU(x, direction):\n",
    "    if direction == 'F':\n",
    "        return max(x, 0)\n",
    "    else:\n",
    "        return float(x > 0)\n",
    "\n",
    "def Lin(x, direction):\n",
    "    if direction == 'F':\n",
    "        return x\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def activation(Z, fcn='Lin', direction = 'F'):\n",
    "    A = np.array(list(map(globals()[fcn], Z, np.repeat(direction, Z.shape[0]))))\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d0c8bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96f032e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH- 1 ================================================================================\n",
      "\n",
      "ITER- 1 --------------------------------------------------------------------------------\n",
      "No bias\n",
      "A_0 = array([[1.],\n",
      "       [0.]])\n",
      "\n",
      "Input -> Hidden\n",
      "    Z_1 = array([[ 1.],\n",
      "       [-1.]])\n",
      "    A_1 = array([[ 0.4621],\n",
      "       [-0.4621]])\n",
      "\n",
      "Hidden -> Output\n",
      "No bias\n",
      "    Z_2 = array([[0.4621]])\n",
      "    A_2 = array([[0.6135]])\n",
      "\n",
      "Error = array([[0.0064]])\n",
      "\n",
      "Output -> Hidden\n",
      "    dE_dw1 = array([[ 0.0124],\n",
      "       [-0.0124]])\n",
      "\n",
      "Hidden -> Input\n",
      "    dE_dw0 = array([[0.0106],\n",
      "       [0.0106]])\n",
      "\n",
      "Weight update\n",
      "    W_1 = array([[ 0.9988, -0.0012],\n",
      "       [ 1.0012,  0.0012]])\n",
      "    W_0 = array([[ 0.9989, -1.0011],\n",
      "       [-1.0011, -1.0011]])\n",
      "\n",
      "ITER- 2 --------------------------------------------------------------------------------\n",
      "No bias\n",
      "A_0 = array([[1.],\n",
      "       [1.]])\n",
      "\n",
      "Input -> Hidden\n",
      "    Z_1 = array([[-0.0021],\n",
      "       [-2.0021]])\n",
      "    A_1 = array([[-0.0011],\n",
      "       [-0.762 ]])\n",
      "\n",
      "Hidden -> Output\n",
      "No bias\n",
      "    Z_2 = array([[-0.0001],\n",
      "       [-0.002 ]])\n",
      "    A_2 = array([[0.5   ],\n",
      "       [0.4995]])\n",
      "\n",
      "Error = array([[0.125 ],\n",
      "       [0.1253]])\n",
      "\n",
      "Output -> Hidden\n",
      "    dE_dw1 = array([[0.0001],\n",
      "       [0.0954]])\n",
      "\n",
      "Hidden -> Input\n",
      "    dE_dw0 = array([[-0.0623],\n",
      "       [-0.0263]])\n",
      "\n",
      "Weight update\n",
      "    W_1 = array([[ 0.9987, -0.0013],\n",
      "       [ 0.9917, -0.0083]])\n",
      "    W_0 = array([[ 1.0052, -0.9948],\n",
      "       [-0.9984, -0.9984]])\n"
     ]
    }
   ],
   "source": [
    "for ep in range(MAX_EPOCHS):\n",
    "    print('\\nEPOCH-', ep+1, '='*80)\n",
    "    for itr, (x, y) in enumerate(zip(X.T, t.T)):\n",
    "        print('\\nITER-', itr+1, '-'*80)\n",
    "        \n",
    "        ### Forward pass (Input -> Hidden)\n",
    "        if X.shape[0] == W_0.shape[1]:\n",
    "            print('No bias')\n",
    "            A_0 = x.reshape(-1, 1)\n",
    "        else:\n",
    "            print('Pad bias at top of input')\n",
    "            A_0 = np.vstack((np.ones((1, x.shape[1])), x))\n",
    "        print(f'{A_0 = }')\n",
    "\n",
    "        print('\\nInput -> Hidden')\n",
    "        Z_1 = (W_0 @ A_0).reshape(-1, 1)\n",
    "        print(f'    {Z_1 = }')\n",
    "        A_1 = activation(Z_1, f_1)\n",
    "        print(f'    {A_1 = }')\n",
    "        \n",
    "        ### Forward pass (Hidden -> Output)\n",
    "        print('\\nHidden -> Output')\n",
    "        if A_1.shape[0] == W_1.shape[1]:\n",
    "            print('No bias')\n",
    "        else:\n",
    "            print('Pad bias at top of A1')\n",
    "            A_1 = np.vstack((np.ones((1, A_1.shape[1])), A_1))\n",
    "            print(f'    {A_1 = }')\n",
    "\n",
    "        Z_2 = (W_1 @ A_1).reshape(-1, 1)\n",
    "        print(f'    {Z_2 = }')\n",
    "        A_2 = activation(Z_2, f_2)  \n",
    "        print(f'    {A_2 = }')\n",
    "        \n",
    "        ### Backward pass (Output -> Hidden)\n",
    "        Error = 0.5*(A_2 - y)**2\n",
    "        print(f'\\n{Error = }')\n",
    "        \n",
    "        print('\\nOutput -> Hidden')\n",
    "        dE_dw1 = (A_2 - y) * activation(Z_2, f_2, 'B') * A_1\n",
    "        print(f'    {dE_dw1 = }')\n",
    "        \n",
    "        ### Backward pass  (Hidden -> Input)\n",
    "        print('\\nHidden -> Input')\n",
    "        if A_1.shape[0] == W_1.shape[1]: # No bias in layer-1\n",
    "            dE_dw0 = (A_2 - y) * activation(Z_2, f_2, 'B') * (W_1 * activation(Z_1, f_1, 'B')) @ A_0 \n",
    "        else:\n",
    "            dE_dw0 = (A_2 - y) * activation(Z_2, f_2, 'B') * (W_1[:, 1:] * activation(Z_1, f_1, 'B')) @ A_0 \n",
    "        print(f'    {dE_dw0 = }')\n",
    "        \n",
    "        ### Update weights\n",
    "        print('\\nWeight update')\n",
    "        W_1 = W_1 - lr*dE_dw1\n",
    "        print(f'    {W_1 = }')\n",
    "        W_0 = W_0 - lr*dE_dw0\n",
    "        print(f'    {W_0 = }')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
